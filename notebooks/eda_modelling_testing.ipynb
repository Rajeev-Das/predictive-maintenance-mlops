{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8de9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc64c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# There are 26 columns: 1-2 are unit/cycle, 3-5 operational settings, 6-26 are sensors (1 to 21)\n",
    "# The columns in the txt files are:\n",
    "#   1: unit\n",
    "#   2: cycle\n",
    "#   3: op_setting_1\n",
    "#   4: op_setting_2\n",
    "#   5: op_setting_3\n",
    "#   6-26: sensor_1 to sensor_21\n",
    "col_names = [\n",
    "    'unit', 'cycle',\n",
    "    'op_setting_1', 'op_setting_2', 'op_setting_3',\n",
    "    'sensor_1', 'sensor_2', 'sensor_3', 'sensor_4', 'sensor_5',\n",
    "    'sensor_6', 'sensor_7', 'sensor_8', 'sensor_9', 'sensor_10',\n",
    "    'sensor_11', 'sensor_12', 'sensor_13', 'sensor_14', 'sensor_15',\n",
    "    'sensor_16', 'sensor_17', 'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21'\n",
    "]\n",
    "train = pd.read_csv('../data/CMAPSSData/train_FD001.txt', sep='\\\\s+', header=None, names=col_names, index_col=None)\n",
    "test = pd.read_csv('../data/CMAPSSData/test_FD001.txt', sep='\\\\s+', header=None, names=col_names)\n",
    "rul = pd.read_csv('../data/CMAPSSData/RUL_FD001.txt', sep='\\\\s+', names=['RUL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adacea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73361ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sensor_6'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1f36a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for missing values\n",
    "print(train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    if col in ['op_setting_1', 'op_setting_2']:\n",
    "        continue  # Skip op_setting_1 and op_setting_2 as these are important settings\n",
    "    # Consider a column \"constant\" if it has only one unique value,\n",
    "    # or if its standard deviation is very small (e.g., < 0.002), \n",
    "    # or if its min and max are extremely close (difference < 0.02)\n",
    "    std = train[col].std()\n",
    "    min_val = train[col].min()\n",
    "    max_val = train[col].max()\n",
    "    if (\n",
    "        train[col].nunique() == 1\n",
    "        or std < 0.002\n",
    "        or abs(max_val - min_val) < 0.02\n",
    "    ):\n",
    "        print(f\"{col} is constant or nearly constant and should be dropped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a37dc7d",
   "metadata": {},
   "source": [
    "Sensors like sensor_1, sensor_5, op_setting_3, sensor_6, sensor_10, sensor_16, sensor_18, sensor_19 show either 0 std or a tiny range—these are likely constant and not useful as features.\n",
    "\n",
    "Drop those for modeling, as they don't provide predictive signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2bc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'sensor_1', 'sensor_5', 'sensor_6', # Added sensor 6\n",
    "    'sensor_10', 'sensor_16', \n",
    "    'sensor_18', 'sensor_19', 'op_setting_3'  # op_setting_3 appears to be constant at 100.0\n",
    "    # 'op_setting_2' # Removed from the list as it has a big range of values though standard deviation is around 0\n",
    "]\n",
    "train = train.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique engines\n",
    "print(\"Train units:\", train['unit'].nunique())\n",
    "print(\"Test units:\", test['unit'].nunique())\n",
    "\n",
    "# Distribution of cycles per engine\n",
    "cycles_per_engine = train.groupby('unit')['cycle'].max()\n",
    "print(cycles_per_engine.describe())\n",
    "\n",
    "cycles_per_engine.hist(bins=30)\n",
    "plt.xlabel('Number of cycles until failure')\n",
    "plt.ylabel('Number of Engines')\n",
    "plt.title('Engine Lifetime Distribution (FD001)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f9e0c",
   "metadata": {},
   "source": [
    "For each row in the training set, generate the RUL label as $$\\mathrm{RUL} = \\max\\_cycle_{\\mathrm{engine}} - \\mathrm{cycle}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['max_cycle'] = train.groupby('unit')['cycle'].transform('max')\n",
    "train['RUL'] = train['max_cycle'] - train['cycle']\n",
    "processed = train.drop(columns='max_cycle')\n",
    "\n",
    "processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217be02c",
   "metadata": {},
   "source": [
    "Rolling Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_rolling_stats(df, group_col, feature_cols, window=5):\n",
    "    \"\"\"\n",
    "    Adds rolling mean, std, min, max, and trend for each feature in feature_cols grouped by group_col.\n",
    "    \"\"\"\n",
    "    result_df = df.copy()\n",
    "    for feature in feature_cols:\n",
    "        # Rolling mean\n",
    "        result_df[f'{feature}_mean{window}'] = (\n",
    "            result_df.groupby(group_col)[feature]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean().reset_index(0, drop=True)\n",
    "        )\n",
    "        # Rolling std\n",
    "        result_df[f'{feature}_std{window}'] = (\n",
    "            result_df.groupby(group_col)[feature]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .std().reset_index(0, drop=True)\n",
    "        )\n",
    "        # Rolling min\n",
    "        result_df[f'{feature}_min{window}'] = (\n",
    "            result_df.groupby(group_col)[feature]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .min().reset_index(0, drop=True)\n",
    "        )\n",
    "        # Rolling max\n",
    "        result_df[f'{feature}_max{window}'] = (\n",
    "            result_df.groupby(group_col)[feature]\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .max().reset_index(0, drop=True)\n",
    "        )\n",
    "        # Rolling trend/slope\n",
    "        def rolling_trend(x):\n",
    "            idx = np.arange(len(x)).reshape(-1,1)\n",
    "            if len(x) < 2:\n",
    "                return 0.0\n",
    "            return LinearRegression().fit(idx, x.values.reshape(-1,1)).coef_[0]\n",
    "        result_df[f'{feature}_trend{window}'] = (\n",
    "            result_df.groupby(group_col)[feature]\n",
    "            .rolling(window=window, min_periods=2)\n",
    "            .apply(rolling_trend, raw=False)\n",
    "            .reset_index(0, drop=True)\n",
    "        )\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cccd510",
   "metadata": {},
   "source": [
    "Sensor Selection and Correlation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_vs_cycle(df, unit_col, sensors, unit_id):\n",
    "    \"\"\"\n",
    "    Plots sensor values over cycles for a given engine/unit.\n",
    "    \"\"\"\n",
    "    for sensor in sensors:\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        subset = df[df[unit_col] == unit_id]\n",
    "        plt.plot(subset['cycle'], subset[sensor])\n",
    "        plt.title(f'{sensor} over cycles - Engine {unit_id}')\n",
    "        plt.xlabel('Cycle')\n",
    "        plt.ylabel(sensor)\n",
    "        plt.show()\n",
    "\n",
    "def plot_sensor_vs_rul(df, unit_col, sensors, unit_id):\n",
    "    \"\"\"\n",
    "    Plots sensor values against RUL for a given engine/unit.\n",
    "    \"\"\"\n",
    "    for sensor in sensors:\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        subset = df[df[unit_col] == unit_id]\n",
    "        plt.plot(subset['RUL'], subset[sensor])\n",
    "\n",
    "        plt.title(f'{sensor} vs. RUL - Engine {unit_id}')\n",
    "        plt.xlabel('RUL')\n",
    "        plt.ylabel(sensor)\n",
    "        plt.gca().invert_xaxis()\n",
    "        plt.show()\n",
    "\n",
    "def sensor_rul_correlation(df, sensor_cols):\n",
    "    \"\"\"\n",
    "    Computes correlation between each sensor and RUL, prints sorted (desc).\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    for sensor in sensor_cols:\n",
    "        corr = df[sensor].corr(df['RUL'])\n",
    "        correlations.append((sensor, corr))\n",
    "    correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    print(\"Sensor correlations with RUL (descending):\")\n",
    "    for sensor, corr in correlations:\n",
    "        print(f\"{sensor}: {corr:.3f}\")\n",
    "    return correlations  # for downstream filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensors_to_engineer filtered for your dataset (excluding dropped/constant ones)\n",
    "sensors_to_engineer = [col for col in processed.columns if col.startswith('sensor') and col not in drop_cols]\n",
    "\n",
    "# Add rolling statistics (window = 5)\n",
    "processed_eng = add_rolling_stats(processed, group_col='unit', feature_cols=sensors_to_engineer, window=5)\n",
    "\n",
    "# Visualizations for unit 1 (or any engine of interest)\n",
    "plot_sensor_vs_cycle(processed_eng, unit_col='unit', sensors=sensors_to_engineer, unit_id=30)\n",
    "plot_sensor_vs_rul(processed_eng, unit_col='unit', sensors=sensors_to_engineer, unit_id=30)\n",
    "\n",
    "# Correlations to help select sensors\n",
    "correlations = sensor_rul_correlation(processed_eng, sensors_to_engineer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732bb04",
   "metadata": {},
   "source": [
    "#### Interpretation of RUL Correlation Results\n",
    "Sensors most correlated with RUL:\n",
    "(Magnitude reflects how strongly sensor readings change as an engine approaches failure.)\n",
    "\n",
    "| Rank | Sensor     | Correlation with RUL | Importance        |\n",
    "|------|------------|----------------------|-------------------|\n",
    "| 1    | sensor_11  | -0.696               | Very Strong       |\n",
    "| 2    | sensor_4   | -0.679               | Very Strong       |\n",
    "| 3    | sensor_12  | 0.672                | Very Strong       |\n",
    "| 4    | sensor_7   | 0.657                | Strong            |\n",
    "| 5    | sensor_15  | -0.643               | Strong            |\n",
    "| 6    | sensor_21  | 0.636                | Strong            |\n",
    "| 7    | sensor_20  | 0.629                | Strong            |\n",
    "| 8    | sensor_2   | -0.606               | Strong            |\n",
    "| 9    | sensor_17  | -0.606               | Strong            |\n",
    "| 10   | sensor_3   | -0.585               | Strong            |\n",
    "| 11   | sensor_8   | -0.564               | Moderate-Strong   |\n",
    "| 12   | sensor_13  | -0.563               | Moderate-Strong   |\n",
    "| 13   | sensor_9   | -0.390               | Moderate          |\n",
    "| 14   | sensor_14  | -0.307               | Medium            |\n",
    "\n",
    "Negative correlations (e.g., sensor_11, sensor_4, etc.):\n",
    "As the engine approaches failure (RUL decreases), sensor value decreases.\n",
    "\n",
    "Positive correlations (e.g., sensor_12, sensor_7, etc.):\n",
    "As the engine approaches failure, sensor value increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb729b8",
   "metadata": {},
   "source": [
    "I've plotted sensor_11 and sensor_4 against RUL for engine 30.\n",
    "The correlation analysis said these features have strong negative correlation with RUL across the whole dataset, so:\n",
    "\n",
    "Expectation: As RUL decreases (i.e., engine ages), sensor value should decrease.\n",
    "\n",
    "What you see: In the graphs, as RUL decreases (moving right to left), the sensor value actually increases.\n",
    "\n",
    "#### Why This Apparent Contradiction?\n",
    "1. Direction of the X-axis:\n",
    "    In the graphs, RUL goes from 200 (left) to 0 (right).\n",
    "\n",
    "    As time progresses (engine approaches failure), RUL decreases—so the rightmost end is near failure.\n",
    "    As you move right, you get closer to failure.\n",
    "\n",
    "2. Negative Correlation — What It Actually Means\n",
    "    Negative correlation means:\n",
    "\n",
    "    Across the entire dataset, when RUL is higher, the sensor value is lower.\n",
    "\n",
    "    Or equivalently, as RUL decreases, the sensor value increases.\n",
    "\n",
    "    This matches exactly what your plots are showing:\n",
    "    For lower RUL (engine near failure, right side), sensor readings are higher than at high RUL.\n",
    "\n",
    "#### How to Read These Plots:\n",
    "* On your x-axis: left (high RUL) → right (low RUL)\n",
    "\n",
    "* On your y-axis: sensor reading\n",
    "\n",
    "As you go right (engine nears failure), the sensor value goes up.\n",
    "\n",
    "This means:\n",
    "\n",
    "* Lower RUL → Higher sensor reading\n",
    "* Higher RUL → Lower sensor reading\n",
    "\n",
    "This matches a negative correlation: when RUL is lower, the sensor value is higher (the two vary inversely).\n",
    "\n",
    "#### Summary Table\n",
    "| Correlation (RUL, Sensor) | What It Means                      | What To See in Plot                |\n",
    "|---------------------------|------------------------------------|------------------------------------|\n",
    "| Negative (e.g., -0.69)    | As RUL decreases, sensor ↑         | Right side of plot: sensor ↑       |\n",
    "| Positive (e.g., +0.60)    | As RUL decreases, sensor ↓         | Right side of plot: sensor ↓       |\n",
    "\n",
    "#### Conclusion\n",
    "Negative correlation between RUL and the sensor value (e.g., corr = -0.69) means:\n",
    "\n",
    "* As RUL decreases (engine gets closer to failure), sensor value increases.\n",
    "\n",
    "* As RUL increases (engine is “healthier”), sensor value decreases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f98d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5294b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5  # Try window = 10 for longer-term trend features\n",
    "feature_sensors = ['sensor_11', 'sensor_7', 'sensor_12', 'sensor_15', 'sensor_21', 'sensor_4']  # as per RUL ranking\n",
    "\n",
    "for sensor in feature_sensors:\n",
    "    processed[f'{sensor}_rollmean'] = (\n",
    "        processed.groupby('unit')[sensor]\n",
    "        .rolling(window, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    processed[f'{sensor}_rollstd'] = (\n",
    "        processed.groupby('unit')[sensor]\n",
    "        .rolling(window, min_periods=1)\n",
    "        .std()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "def rolling_slope(series, window):\n",
    "    def linreg(x):\n",
    "        if len(x) < 2:\n",
    "            return 0\n",
    "        x_idx = np.arange(len(x))\n",
    "        slope = np.polyfit(x_idx, x, 1)[0]\n",
    "        return slope\n",
    "    return series.rolling(window, min_periods=2).apply(linreg, raw=True)\n",
    "\n",
    "for sensor in feature_sensors:\n",
    "    processed[f'{sensor}_slope'] = (\n",
    "        processed.groupby('unit')[sensor]\n",
    "        .apply(lambda x: rolling_slope(x, window))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76659e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [col for col in processed.columns if col.startswith('sensor_')]\n",
    "sensor_stds = processed[sensor_cols].std().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.barplot(x=sensor_stds.index, y=sensor_stds.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Std Deviation')\n",
    "plt.title('Sensor Standard Deviation (Variance)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d805d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sensors = [col for col in sensor_cols if processed[col].std() > 0.1]  # Adjust threshold as needed\n",
    "corr = processed[active_sensors].corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, cmap='coolwarm', annot=False)\n",
    "plt.title('Active Sensor Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcea88e2",
   "metadata": {},
   "source": [
    "* Sensor standard deviation plot:\n",
    "\n",
    "    * Shows which sensors are active (high std), which are nearly constant (low std).\n",
    "\n",
    "    * Drop sensors with very low variance—they add little or no predictive power.\n",
    "\n",
    "* Correlation matrix:\n",
    "\n",
    "    * Many sensors are strongly correlated (|corr| > 0.7–0.8).\n",
    "\n",
    "    * Example: sensor_4, sensor_11, sensor_12, sensor_7, sensor_21 form a “core group” of highly correlated signals.\n",
    "\n",
    "    * Redundant features inflate model complexity and can degrade performance (especially for linear models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c53714",
   "metadata": {},
   "source": [
    "Robust, automated feature selection pipeline based on your criteria for sensor data, ready for production or iterative refinement.\n",
    "This will:\n",
    "\n",
    "* Drop low-variance features\n",
    "\n",
    "* Select features with high absolute correlation to RUL\n",
    "\n",
    "* Drop one of each highly correlated pair (by |corr| > 0.9), keeping the one with higher RUL-correlation\n",
    "\n",
    "* Optionally, add trend/rolling features (but not when redundant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd10eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def automated_feature_selection(\n",
    "    df, \n",
    "    target_col='RUL', \n",
    "    op_set_cols=['op_setting_1', 'op_setting_2'], \n",
    "    sensor_prefix='sensor_',\n",
    "    std_threshold=0.1,\n",
    "    top_k=8,\n",
    "    corr_cutoff=0.9,\n",
    "    add_rollmean=False,\n",
    "    add_slope=False\n",
    "):\n",
    "    # 1. Find sensor columns\n",
    "    sensor_cols = [col for col in df.columns if col.startswith(sensor_prefix) and df[col].dtype != 'object']\n",
    "\n",
    "    # 2. Drop low-variance sensors\n",
    "    active_sensors = [col for col in sensor_cols if df[col].std() > std_threshold]\n",
    "\n",
    "    # 3. Correlation to RUL (absolute values)\n",
    "    sensor_rul_corr = {col: abs(df[col].corr(df[target_col])) for col in active_sensors}\n",
    "    sorted_sensors = sorted(sensor_rul_corr, key=lambda col: sensor_rul_corr[col], reverse=True)\n",
    "    # Keep top K RUL-informative sensors\n",
    "    selected = sorted_sensors[:top_k]\n",
    "\n",
    "    # 4. Remove one of each highly correlated pair (|corr| > corr_cutoff)\n",
    "    keep = []\n",
    "    for col in selected:\n",
    "        redundant = False\n",
    "        for k in keep:\n",
    "            pairwise_corr = abs(df[[col, k]].corr().iloc[0,1])\n",
    "            if pairwise_corr > corr_cutoff:\n",
    "                redundant = True\n",
    "                break\n",
    "        if not redundant:\n",
    "            keep.append(col)\n",
    "    selected = keep\n",
    "\n",
    "    # 5. Optional: add rollmean/slope features for selected sensors (non-redundant only)\n",
    "    extra = []\n",
    "    if add_rollmean:\n",
    "        for col in selected:\n",
    "            roll_col = f\"{col}_rollmean\"\n",
    "            if roll_col in df.columns:\n",
    "                extra.append(roll_col)\n",
    "    if add_slope:\n",
    "        for col in selected:\n",
    "            slope_col = f\"{col}_slope\"\n",
    "            if slope_col in df.columns:\n",
    "                extra.append(slope_col)\n",
    "\n",
    "    # 6. Always include operational settings, combine final feature list\n",
    "    final_features = op_set_cols + selected + extra\n",
    "\n",
    "    print(\"Selected features:\", final_features)\n",
    "    return final_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceed35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = automated_feature_selection(\n",
    "    processed,                   # DataFrame with sensor, op setting, and RUL columns\n",
    "    target_col='RUL',\n",
    "    op_set_cols=['op_setting_1', 'op_setting_2'],\n",
    "    std_threshold=0.1,\n",
    "    top_k=10,\n",
    "    corr_cutoff=0.9,             # Remove highly intercorrelated sensors\n",
    "    add_rollmean=True,\n",
    "    add_slope=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647bcacd",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed= processed.dropna()\n",
    "processed.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0b5d3e",
   "metadata": {},
   "source": [
    "Rolling mean/slope with min_periods=1: Usually, only the very first rows for each engine/unit will have enough values to fully calculate a rolling window of size 5 (or your window).\n",
    "\n",
    "Rolling slope (min_periods=2): The very first entry per group is guaranteed to be NaN, since slope requires at least 2 points. For rolling mean, if you set min_periods=1, it should not produce nulls unless you have accidental group issues or missing data upstream.\n",
    "\n",
    "Result: For each engine, the first (window-1) rows for rolling mean, and first row for slope, will have nulls.\n",
    "\n",
    "Removal:\n",
    "* Safest and most common: Simply remove all rows containing any NaNs after rolling/stat features are created.\n",
    "\n",
    "* In this dataset, since these are just the very first few cycles per engine (before any significant degradation or signal), you lose little predictive info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = processed[final_features]\n",
    "y = processed['RUL']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PIPELINE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),              # Normalize features\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_val)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = mean_squared_error(y_val, y_pred)\n",
    "print(f'MAE: {mae:.2f}, RMSE: {rmse:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# X, y assumed to be your final feature matrix and label.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Candidate models and their parameter grids:\n",
    "model_dict = {\n",
    "    \"LinearRegression\": (\n",
    "        LinearRegression(),\n",
    "        {}\n",
    "    ),\n",
    "    \"Ridge\": (\n",
    "        Ridge(),\n",
    "        {'model__alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "    ),\n",
    "    \"Lasso\": (\n",
    "        Lasso(max_iter=10000),\n",
    "        {'model__alpha': [0.01, 0.1, 1.0, 10.0]}\n",
    "    ),\n",
    "    \"RandomForest\": (\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        {'model__n_estimators': [100, 200], 'model__max_depth': [None, 8, 16]}\n",
    "    ),\n",
    "    \"GradientBoosting\": (\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        {'model__n_estimators': [100, 200], 'model__max_depth': [3, 5]}\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Optionally add XGBoost if installed\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    model_dict[\"XGBoost\"] = (\n",
    "        XGBRegressor(random_state=42, verbosity=0),\n",
    "        {'model__n_estimators': [100, 200], 'model__max_depth': [3, 5]}\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"XGBoost is not installed, skipping.\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, (regressor, param_grid) in model_dict.items():\n",
    "    print(f\"GridSearchCV for {model_name}...\")\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),   # Always scale for fair comparison\n",
    "        ('model', regressor)\n",
    "    ])\n",
    "    gs = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        error_score=\"raise\"\n",
    "    )\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_est = gs.best_estimator_\n",
    "    y_pred = best_est.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    results[model_name] = {\n",
    "        'best_params': gs.best_params_,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'model': best_est\n",
    "    }\n",
    "    print(f\"{model_name}: MAE={mae:.2f}, RMSE={rmse:.2f}, Best Params: {gs.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c0fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n=== Summary of Results ===\")\n",
    "for model_name, res in results.items():\n",
    "    print(f\"{model_name}: MAE={res['MAE']:.2f}, RMSE={res['RMSE']:.2f}, Best Params: {res['best_params']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631ba1a",
   "metadata": {},
   "source": [
    "#### Model Comparison Plot (MAE and RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d097128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Collect results for plotting\n",
    "model_names = list(results.keys())\n",
    "mae_values = [results[m]['MAE'] for m in model_names]\n",
    "rmse_values = [results[m]['RMSE'] for m in model_names]\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='MAE', x=model_names, y=mae_values, marker_color='indianred'),\n",
    "    go.Bar(name='RMSE', x=model_names, y=rmse_values, marker_color='royalblue')\n",
    "])\n",
    "fig.update_layout(\n",
    "    title='Model Comparison: MAE and RMSE',\n",
    "    barmode='group',\n",
    "    yaxis_title='Error Value',\n",
    "    template='plotly_white'\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0990f8",
   "metadata": {},
   "source": [
    "#### Residual Histogram for Each Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for model_name, res in results.items():\n",
    "    best_model = res['model']\n",
    "    preds = best_model.predict(X_val)\n",
    "    residuals = y_val - preds\n",
    "    import numpy as np\n",
    "    from scipy.stats import gaussian_kde\n",
    "\n",
    "    # Histogram trace\n",
    "    # Define a color for each model for consistent coloring between histogram and KDE\n",
    "    import plotly.colors as pc\n",
    "    color_palette = pc.qualitative.Plotly\n",
    "    color_idx = model_names.index(model_name) % len(color_palette)\n",
    "    color = color_palette[color_idx]\n",
    "\n",
    "    # Histogram trace (with model-specific color)\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=residuals,\n",
    "            nbinsx=50,\n",
    "            name=f\"{model_name} Histogram\",\n",
    "            opacity=0.4,\n",
    "            marker=dict(color=color, line=dict(width=0)),\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # KDE curve trace (with same color)\n",
    "    kde = gaussian_kde(residuals)\n",
    "    x_range = np.linspace(residuals.min(), residuals.max(), 200)\n",
    "    # Scale KDE to match histogram area\n",
    "    hist_area = len(residuals) * (residuals.max() - residuals.min()) / 50\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_range,\n",
    "            y=kde(x_range) * hist_area,\n",
    "            mode='lines',\n",
    "            name=f\"{model_name} KDE\",\n",
    "            line=dict(width=3, color=color),\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Residuals Histogram for Each Model\",\n",
    "    template='plotly_white',\n",
    "    barmode='overlay',\n",
    "    xaxis_title=\"Residual (True RUL - Predicted RUL)\",\n",
    "    yaxis_title=\"Count\",\n",
    "    legend_title=\"Model\",\n",
    "    height=500,\n",
    "    width=800\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad8bd1",
   "metadata": {},
   "source": [
    "#### Feature Importance Barplots (Tree-Based Models Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc864b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all feature importances into a single interactive plot with legend\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Collect feature importances for all tree-based models\n",
    "feature_importance_traces = []\n",
    "for model_name, res in results.items():\n",
    "    model = res['model']\n",
    "    if hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "        importances = model.named_steps['model'].feature_importances_\n",
    "        trace = go.Bar(\n",
    "            x=importances,\n",
    "            y=X_val.columns,\n",
    "            orientation='h',\n",
    "            name=model_name,\n",
    "            visible=True if len(feature_importance_traces) == 0 else 'legendonly'  # Show first by default\n",
    "        )\n",
    "        feature_importance_traces.append(trace)\n",
    "\n",
    "if feature_importance_traces:\n",
    "    fig = go.Figure(feature_importance_traces)\n",
    "    fig.update_layout(\n",
    "        title=\"Feature Importance Comparison (Tree-Based Models)\",\n",
    "        barmode='group',\n",
    "        template='plotly_white',\n",
    "        yaxis={'categoryorder': 'total ascending'},\n",
    "        xaxis_title='Importance',\n",
    "        yaxis_title='Feature',\n",
    "        legend_title='Model'\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No tree-based models with feature_importances_ found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a26fe8",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fde214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use all available data for final training\n",
    "X_final = processed[final_features]\n",
    "y_final = processed['RUL']\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 300],\n",
    "    'model__max_depth': [6, 8, 12],\n",
    "    'model__max_features': ['sqrt', 'log2'],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='neg_mean_absolute_error', n_jobs=-1, error_score='raise')\n",
    "grid.fit(X_final, y_final)\n",
    "print(\"Best params:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac155d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "# Update best parameters for your RandomForest\n",
    "best_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 8,\n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 4,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Use your chosen features and RUL column\n",
    "X_final = processed[final_features]\n",
    "y_final = processed['RUL']\n",
    "\n",
    "# Full model pipeline\n",
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestRegressor(**best_params))\n",
    "])\n",
    "\n",
    "# Train on all data\n",
    "final_pipeline.fit(X_final, y_final)\n",
    "\n",
    "# Save model pipeline for deployment/inference\n",
    "joblib.dump(final_pipeline, \"../model/model_rf_pipeline_best.joblib\")\n",
    "print(\"Final model retrained and saved as model_rf_pipeline_best.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6141095",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ---- PARAMETERS ----\n",
    "WINDOW = 5\n",
    "\n",
    "final_features = [\n",
    "    'op_setting_1', 'op_setting_2',\n",
    "    'sensor_4_rollmean', 'sensor_12', 'sensor_7', 'sensor_21', 'sensor_20',\n",
    "    'sensor_12_rollmean', 'sensor_7_rollmean', 'sensor_21_rollmean',\n",
    "    'sensor_12_slope', 'sensor_7_slope', 'sensor_21_slope'\n",
    "]\n",
    "\n",
    "# --- UTILS ---\n",
    "def add_rolling_mean(df, feature, group='unit', window=5):\n",
    "    return (\n",
    "        df.groupby(group)[feature]\n",
    "        .rolling(window, min_periods=1)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "def rolling_slope(series, window):\n",
    "    def linreg(x):\n",
    "        if len(x) < 2:\n",
    "            return np.nan\n",
    "        x_idx = np.arange(len(x))\n",
    "        slope = np.polyfit(x_idx, x, 1)[0]\n",
    "        return slope\n",
    "    return series.rolling(window, min_periods=2).apply(linreg, raw=True)\n",
    "\n",
    "def add_rolling_slope(df, feature, group='unit', window=5):\n",
    "    return (\n",
    "        df.groupby(group)[feature]\n",
    "        .apply(lambda x: rolling_slope(x, window))\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "# --- 1. LOAD DATA ---\n",
    "test_raw = pd.read_csv('../data/CMAPSSData/test_FD001.txt', sep='\\\\s+', header=None, names=col_names)\n",
    "col_names = ['unit', 'cycle', 'op_setting_1', 'op_setting_2', 'op_setting_3'] + [f'sensor_{i}' for i in range(1, 22)]\n",
    "test_raw.columns = col_names\n",
    "\n",
    "# --- 2. DROP UNUSED CONSTANT COLUMNS (must match your training pipeline!) ---\n",
    "drop_cols = ['op_setting_3', 'sensor_1', 'sensor_5', 'sensor_6', 'sensor_10', 'sensor_16', 'sensor_18', 'sensor_19']\n",
    "test = test_raw.drop(columns=drop_cols)\n",
    "\n",
    "# --- 3. COMPUTE ROLLING MEANS ---\n",
    "for sensor in ['sensor_4', 'sensor_12', 'sensor_7', 'sensor_21']:\n",
    "    test[f'{sensor}_rollmean'] = add_rolling_mean(test, sensor, window=WINDOW)\n",
    "\n",
    "# --- 4. COMPUTE ROLLING SLOPE ---\n",
    "for sensor in ['sensor_12', 'sensor_7', 'sensor_21']:\n",
    "    test[f'{sensor}_slope'] = add_rolling_slope(test, sensor, window=WINDOW)\n",
    "\n",
    "# --- 5. DROP ROWS WITH ANY NULL IN THE SELECTED FEATURES ---\n",
    "test = test.dropna(subset=final_features)\n",
    "\n",
    "# --- 6. FOR EACH ENGINE, RETAIN ONLY THE LAST CYCLE (after feature engineering) ---\n",
    "test_last = test.groupby('unit').tail(1).reset_index(drop=True)\n",
    "\n",
    "# --- 7. ALIGN FINAL FEATURES, PREDICT RUL ---\n",
    "X_test = test_last[final_features]\n",
    "model = joblib.load('../model/model_rf_pipeline_best.joblib')  # Or your specific filename\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# --- 8. LOAD TRUE RUL VALUES and COMPARE ---\n",
    "true_rul = pd.read_csv('../data/CMAPSSData/RUL_FD001.txt', sep='\\\\s+', header=None, names=['true_RUL'])\n",
    "y_true = true_rul['true_RUL'].values\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "print(f\"Test set MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "\n",
    "# For a quick comparison table\n",
    "results_df = pd.DataFrame({\n",
    "    'unit': test_last['unit'], 'true_RUL': y_true, 'predicted_RUL': y_pred\n",
    "})\n",
    "print(results_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming results_df with columns: unit, true_RUL, predicted_RUL\n",
    "results_df['residual'] = results_df['true_RUL'] - results_df['predicted_RUL']\n",
    "results_df['abs_error'] = results_df['residual'].abs()\n",
    "\n",
    "# (a) Scatter True vs. Predicted RUL\n",
    "fig = px.scatter(\n",
    "    results_df, x='true_RUL', y='predicted_RUL', hover_data=['unit', 'residual'],\n",
    "    title=\"Predicted RUL vs. True RUL (Test Set)\",\n",
    "    trendline=\"ols\", template=\"plotly_white\"\n",
    ")\n",
    "fig.add_shape(type='line', x0=0, y0=0, x1=results_df['true_RUL'].max(), y1=results_df['true_RUL'].max(),\n",
    "              line=dict(color='gray', dash='dash'))\n",
    "fig.update_layout(\n",
    "    xaxis_title='True RUL', yaxis_title='Predicted RUL',\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# (b) Residual Histogram\n",
    "fig2 = px.histogram(\n",
    "    results_df, x='residual', nbins=30,\n",
    "    title=\"Distribution of Residuals (True RUL - Predicted RUL)\",\n",
    "    labels={'residual':'Residual (Error)'},\n",
    "    marginal=\"box\", template=\"plotly_white\"\n",
    ")\n",
    "fig2.update_layout(bargap=0.2)\n",
    "fig2.show()\n",
    "\n",
    "# (c) Absolute Error Histogram\n",
    "fig3 = px.histogram(\n",
    "    results_df, x='abs_error', nbins=30,\n",
    "    title=\"Distribution of Absolute Errors |True RUL - Predicted RUL|\",\n",
    "    labels={'abs_error':'Absolute Error'},\n",
    "    marginal=\"box\", template=\"plotly_white\"\n",
    ")\n",
    "fig3.update_layout(bargap=0.2)\n",
    "fig3.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed9a9ee",
   "metadata": {},
   "source": [
    "#### Interpretation of Model Performance on Test Set\n",
    "1. **Predicted RUL vs. True RUL Scatter Plot**\n",
    "* What it shows:\n",
    "    Each point represents a test engine at its final recorded cycle, with its true Remaining Useful Life (RUL) on the x-axis and your model’s predicted RUL on the y-axis.\n",
    "\n",
    "    * Dashed gray line:\n",
    "        Perfect predictions (Predicted RUL = True RUL) would fall exactly on this line.\n",
    "\n",
    "    * Blue trend line:\n",
    "        Shows the linear regression fit of your model’s predictions versus the ideal.\n",
    "\n",
    "    **Interpretation:**\n",
    "    \n",
    "    Most points are reasonably close to the diagonal, indicating good model performance. However, some points, especially for high RUL values, are predicted as larger or smaller than true RUL, showing some over-/under-estimation on certain engines, which is common in this complex prediction task.\n",
    "\n",
    "2. **Residual Distribution Plot**\n",
    "* What it shows:\n",
    "    Histogram of residuals (True RUL – Predicted RUL), with a notched box plot above.\n",
    "\n",
    "    **Interpretation:**\n",
    "\n",
    "    * The center of the distribution is near zero, which is ideal and indicates no systematic bias.\n",
    "\n",
    "    * The spread is moderately symmetric but shows some negative skew (more underestimation; i.e., the model sometimes predicts lower RUL than actual).\n",
    "\n",
    "    * Most residuals are within ±40 cycles.\n",
    "\n",
    "    * A few residuals are more extreme—these are outliers where the model under/over-predicted more strongly, which often occurs for irregular or highly variable test cases.\n",
    "\n",
    "3. **Absolute Error Distribution Plot**\n",
    "* What it shows:\n",
    "    Histogram and box plot of absolute errors |True RUL – Predicted RUL|.\n",
    "\n",
    "    **Interpretation:**\n",
    "\n",
    "    * Most absolute errors are below 40 cycles, with a concentration in the 10–30 range.\n",
    "\n",
    "    * The box plot confirms that the median absolute error is low and most predictions are within a reasonable error bound.\n",
    "\n",
    "    * The presence of some larger errors (outliers) indicates that, while the model handles the majority of cases well, a few engines are more difficult to predict exactly—likely due to unique sensor progression or boundary RUL values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Summary of Model Evaluation:\n",
    "\n",
    "The model demonstrates strong predictive performance on the test set, as evidenced by the error metrics (Test MAE: 25.31, RMSE: 33.44) and the distributional plots. The scatter plot of predicted vs. true RUL values shows that most predictions are close to the ideal line, confirming the model's ability to track the actual degradation pattern of most engines.\n",
    "\n",
    "The residual and absolute error histograms indicate that the majority of prediction errors lie within a reasonable range, and there is no obvious systematic over- or under-prediction. While a few predictions result in larger errors, the central tendency and spread are both appropriate for the complexity of the task and the information available.\n",
    "\n",
    "Conclusion:\n",
    "With the inclusion of rolling statistical features, the model substantially improves over baselines and predicts RUL with low mean errors. This demonstrates both the potential of data-driven prognostics and the effectiveness of carefully engineered features in supporting remaining useful life estimation for complex systems like aircraft engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0050e59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
